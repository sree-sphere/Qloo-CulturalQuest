# Cultour ðŸŒ

A gamified cultural exploration platform that helps new migrants and cultural enthusiasts discover authentic local experiences through AI-powered recommendations, interactive chat, and immersive rewards system.

Cultour blends Qlooâ€™s Taste AIâ„¢ with OpenAIâ€™s ChatGPT and ElevenLabs TTS to redefine personalized discovery. Cultour uses advanced multi-stage recommendationâ€‘system techniques â€” semantic embeddings, contextual bandit learning (a form of online reinforcement learning), and MMR-based diversification â€” to balance affinity and novelty. The experience is wrapped in a points-and-badges UX to drive discovery through exploration.

---

## ðŸŽ¯ Why Cultour?

### Inspiration

As a migrant child in Austin, TX in late 2000s, I relied on a site called **[Sulekha](https://us.sulekha.com/)**â€”a one-stop guide to local stores, eateries, rentals, contact details, festivals (melas), and cultural spotsâ€”for navigating life as a migrant. It helped thousands of newcomers build familiarity in a new city through culturally relevant information.

Today, Austin is home to **â‰ˆ296,000 foreign-born residents** (14% of the city's total population, by [Vera Institute](https://vera-institute.files.svdcdn.com/production/downloads/publications/profile-foreign-born-population-austin.pdf)).

**Cultour** evolves that vision with Qlooâ€™s Taste AIâ„¢ and LLMs to deliver real-time, privacy-first recommendations that resonate with usersâ€™ heritage and evolving tastes.

### Character Assets

- The **Sahayak** (meaning â€œhelperâ€) assistant character draws inspiration from the anime/Jâ€‘drama **_Trillion Game_**, where the AI named â€œTurininâ€ guides customers toward their best-fit choices through intuitive intelligence and contextual suggestions.

---

## âœ¨ Features

- **Recommendation System Architecture: Hybrid Multi-Stage Pipeline**
  - **Stage 1**: Semantic Retrieval via Embedding
    1. Computes sentence-level embeddings for all available entities using SentenceTransformer (`all-MiniLM-L6-v2`) with cosine similarity for initial selection
    2. Fast re-ranking with cache & streaming support
  - **Stage 2**: Contextual Bandit scoring via Vowpal Wabbit (CB mode of online **Reinforcement Learning** without state transition)
    1. **Vowpal Wabbit** (CB learning), the engine learns a lightweight contextual bandit model based on past user interactions (includes *quantized embeddings*, tags, cuisine types, price, rating, and derived context features)
    2. Predicts explorationâ€‘aware scores for entities (used in final MMR reâ€‘ranking)
    3. Training pipeline supports feature engineering and vectorized learning with CB-formatted input
  - **Stage 3**: MMR-based diversification with Î»-tunable filtering regarding exploration-exploitation trade-off
    1. Applies **Maximal Marginal Relevance (MMR)** twoâ€‘phase selection to balance **relevance** (Î»â‰ˆ0.7) and **novelty/diversity** (Î»â‰ˆ0.3)  
    2. Supports highâ€‘affinity â€œtopâ€‘kâ€ picks and boosts diversified fillâ€‘ins for rich discovery. `Eg: Picks 3 high-affinity entities + 2 serendipitous ones from new places.`

- **Cultural Gamification**  
  - Points, levels, badges (like â€œFestival of Lights Explorerâ€) via `qloo_gamification_sdk.ts`  
  - User affinity vector updates on interactions (likes/unlikes) with learningâ€‘rate adjustments  

- **AI Chat Assistant**  
  - `chat/route.ts` proxy to ChatGPT, enriched with:  
    - Full API context (entitiesâ€™ descriptions, hours, amenities)  
    - User profile metadata (demographics, preferences, streaks)  
  - Streaming responses with live video/photo backgrounds

- **Assets**
  - **Images:** generated using my profile image as reference, with FLUX.1â€‘Kontextâ€‘Dev space on Hugging Face:  
    https://huggingface.co/spaces/black-forest-labs/FLUX.1-Kontext-Dev  
  - **Videos:** rendered via ChatGPTâ€™s video API.

- **Photo Upload Validation**  
  - Users can upload or capture location-tagged images
  - `/api/extract-gps` routes EXIF extraction via Python `extract_gps.py`  
  - If image was taken within 20â€¯km (20 for demo) of target, user receives points and may earn badges  

- **Textâ€‘toâ€‘Speech Playback**  
  - `/api/tts` (`tts/route.ts`) calls ElevenLabs to generate audio blobs  
  - Synchronized video overlays and fallback to static imagery

- **Modes**  
  - â€œNostalgicâ€ (similarity-based reordering) mode caches & reorders recommendations by userâ€‘liked similarity scores
  - â€œAdventureâ€ (diversity-driven discovery) 
  - â€œSocialâ€ mode filters recommendations by user profile-based affinity vectors and uses chat for itinerary

---

## Tech Stack

- **Frontend**: Next.js + TypeScript + React + Tailwind CSS  
- **Backend**: Next.js API routes (`route.ts`)  
  - `chat/route.ts` â†’ OpenAI Chat API  
  - `tts/route.ts`  â†’ ElevenLabs TTS API  
- **Python ML Engine** (`smart_diversification.py`):
  - `sentence-transformers` for semantic embedding
  - `scikit-learn` for cosine similarity
  - `vowpalwabbit` for contextual bandit training (CB)
  - `MMR (Maximal Marginal Relevance)` diversification with affinity-novelty scoring
  - `NumPy` for vector operations and diversity analytics
- **SDKs**:  
  - `@devma/qloo` + `QlooCulturalGamification`  
- **Environment**:  
  - Conda (`qloo-ts`) for Python  
  - Node.js (â‰¥14) for Next.js  

---

## Folder Tree

```
.
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ qloo_assets/â€¦                       # Avatar Images and Assistant video responses
â”‚   â””â”€â”€ â€¦  
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ chat/route.ts               # ChatGPT API streaming proxy
â”‚   â”‚       â””â”€â”€ tts/route.ts                # ElevenLabs TTS proxy
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ cultural_gamification_ui.tsx    # React Gamification UI component (main)
â”‚   â””â”€â”€ lib/
â”‚       â””â”€â”€ qloo_gamification_sdk.ts        # Qloo SDK wrapper
â”œâ”€â”€ diversification_engine.py                # Offline diversification script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ package.json                            # Node.js deps & scripts
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

## Setup
### Prerequisites

- Node.js 18+
- npm or yarn

### API Keys for:

- Qloo API
- OpenAI GPT
- ElevenLabs

### Environment Variables
Create a .env.local file:
```
NEXT_PUBLIC_QLOO_API_KEY=
OPENAI_API_KEY=
ELEVENLABS_API_KEY=
```

## Installation
Conda Environment (Python)
```
conda create -n qloo-ts python=3.10
conda activate qloo-ts
pip install -r requirements.txt
```
```
# Optional: full reproducibility
conda env export --name qloo-ts > environment.yml
```

Node.js Setup (Next.js + TypeScript): default on http://localhost:3000
```
npm install
npm run dev
```
